# Census Income Prediction â€“ Data Science Technical Assessment

## ğŸ“Œ Problem Statement

The objective of this project is to identify demographic, educational, and employment-related characteristics associated with individuals earning **more or less than $50,000 per year**, using anonymized U.S. Census data.

This work was completed as part of a **Data Scientist Technical Assessment**, with a focus on:

* Sound data science methodology
* Interpretability and communication
* Production-ready, reproducible code

---

## ğŸ“Š Dataset Overview

The dataset originates from the U.S. Census Bureau and consists of approximately **300,000 individuals**, split into predefined training and testing files.

Key characteristics:

* **Training instances:** ~199,523
* **Testing instances:** ~99,762
* **Target imbalance:**

  * â‰¤ $50K â†’ ~93.8%
  * > $50K â†’ ~6.2%
* **Feature types:**

  * Continuous: 7
  * Categorical: 33

Metadata provided by the Census Bureau was explicitly used to guide preprocessing decisions.

---

## âš ï¸ Key Challenges

1. **Severe class imbalance**, making accuracy a misleading metric
2. **High-cardinality categorical features**, leading to dimensionality expansion
3. **Multicollinearity**, introduced by overlapping demographic concepts
4. **Customer-facing requirement**, requiring interpretability and clarity

---

## ğŸ” Exploratory Data Analysis (EDA)

Key findings from EDA:

* Income is strongly associated with age, weeks worked, education level, and occupation group
* Several demographic variables encode overlapping information (e.g., migration and residence history)
* A naive majority-class model achieves **93.8% accuracy**, setting a critical baseline

EDA outputs are documented with visualizations and summary tables in the notebooks.

---

## ğŸ§¹ Data Preparation & Feature Engineering

The following steps were applied consistently to **both training and test datasets**:

* Explicit handling of â€œNot in universeâ€ categories
* Logical grouping of categorical levels based on Census metadata
* One-Hot Encoding with reference-level dropping to avoid dummy variable traps
* Numeric feature scaling for linear models
* Feature diagnostics using:

  * **Correlation analysis (>|0.95|)**
  * **Variance Inflation Factor (VIF)**

Redundant variables were removed only after baseline modeling to avoid premature information loss.

---

## ğŸ¤– Modeling Approach

Two complementary models were developed:

### 1ï¸âƒ£ Logistic Regression (Baseline & Interpretable Model)

* Class imbalance handled via `class_weight='balanced'`
* Used to:

  * Establish baseline performance
  * Interpret feature influence
  * Diagnose multicollinearity impact

### 2ï¸âƒ£ Random Forest (Non-linear Benchmark)

* Captures interaction effects
* Used for performance comparison, not interpretability replacement

---

## ğŸ“ˆ Model Evaluation

Given the imbalanced target, evaluation focused on:

* **Recall (high-income class)**
* **F1-score**
* **ROC-AUC**

### Logistic Regression (Validation Set)

* **ROC-AUC:** ~0.94
* **Recall (>50K):** ~0.89
* Accuracy intentionally sacrificed to improve minority-class detection

This represents a substantial improvement over the majority-class baseline.

---

## ğŸ§  Key Insights

* Employment intensity, education level, and occupation category are the strongest predictors of higher income
* Several demographic variables exhibit semantic multicollinearity
* Logistic regression provided strong discrimination while remaining interpretable
* Random Forest marginally improved recall but reduced transparency

---

## ğŸš§ Limitations & Future Work

* Hyperparameter tuning and threshold optimization were limited by scope
* Advanced imbalance techniques (e.g., SMOTE) could further improve precision
* Feature importance stability could be explored across bootstrap samples

---

## ğŸ“ Repository Structure

```
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_understanding.ipynb
â”‚   â”œâ”€â”€ 02_eda.ipynb
â”‚   â”œâ”€â”€ 03_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 04_modeling.ipynb
â”œâ”€â”€ slides/
â”‚   â””â”€â”€ census_income_presentation.pdf
â”œâ”€â”€ README.md
```

---

## âœ… Final Notes

The goal of this assessment was not model perfection, but rather to:

* Demonstrate a structured data science workflow
* Communicate findings effectively
* Make transparent, defensible modeling decisions

This repository is fully reproducible and designed for collaborative review.
